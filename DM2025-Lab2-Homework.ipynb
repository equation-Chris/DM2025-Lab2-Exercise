{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/equation-Chris/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o dm-lab-2-private-competition.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWpTUYQ3vWJT",
        "outputId": "e4454303-1317-4117-8ff1-c73c9442c0de"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dm-lab-2-private-competition.zip\n",
            "  inflating: data_identification.csv  \n",
            "  inflating: emotion.csv             \n",
            "  inflating: final_posts.json        \n",
            "  inflating: samplesubmission.csv    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPI7mZ0Ntrgl"
      },
      "source": [
        "### **Student Information**\n",
        "Name:\n",
        "\n",
        "Student ID:\n",
        "\n",
        "GitHub ID:\n",
        "\n",
        "Kaggle name:\n",
        "\n",
        "Kaggle private scoreboard snapshot:\n",
        "\n",
        "![pic_ranking.png](https://github.com/equation-Chris/DM2025-Lab2-Exercise/blob/main/pics/pic_ranking.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SD-D1lGtrgn"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q1V-z4_trgn"
      },
      "source": [
        "# **Instructions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGTl4qhJtrgn"
      },
      "source": [
        "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
        "\n",
        "**Environment recommendations to solve lab 2:**\n",
        "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
        "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
        "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
        "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models.\n",
        "\n",
        "## **Phase 1 (30 pts):**\n",
        "\n",
        "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
        "\n",
        "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**.\n",
        "\n",
        "## **Phase 2 (30 pts):**\n",
        "\n",
        "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
        "\n",
        "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**.\n",
        "\n",
        "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
        "\n",
        "## **Phase 3 (40 pts):**\n",
        "\n",
        "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking:\n",
        "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
        "\n",
        "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
        "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
        "\n",
        "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements:\n",
        "* Your preprocessing steps.\n",
        "* The feature engineering steps.\n",
        "* Explanation of your model.\n",
        "\n",
        "* **`Bonus (5 pts):`**\n",
        "    * You will have to describe more detail in the previous steps.\n",
        "    * Mention different things you tried.\n",
        "    * Mention insights you gained.\n",
        "\n",
        "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
        "\n",
        "**`Things to note for Phase 3:`**\n",
        "\n",
        "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
        "\n",
        "* **Push the code used for the competition to your repository**.\n",
        "\n",
        "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
        "\n",
        "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
        "\n",
        "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
        "\n",
        "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
        "\n",
        "## **Deadlines:**\n",
        "\n",
        "![lab2_deadlines](https://github.com/equation-Chris/DM2025-Lab2-Exercise/blob/main/pics/lab2_deadlines.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tHw-pGEtrgo"
      },
      "source": [
        "---\n",
        "\n",
        "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
        "\n",
        "You can delete the syntax suggestions after you use them.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtZEvhxytrgo"
      },
      "source": [
        "***\n",
        "\n",
        "# **Project Report**\n",
        "\n",
        "**Syntax:** `#` creates the largest heading (H1).\n",
        "\n",
        "---\n",
        "**Syntax:** `---` creates a horizontal rule (a separator line).\n",
        "\n",
        "## 1. Model Development (10 pts Required)\n",
        "\n",
        "**Syntax:** `##` creates a secondary heading (H2).\n",
        "\n",
        "**Describe briefly each section, you can add graphs/charts to support your explanations.**\n",
        "\n",
        "### 1.1 Preprocessing Steps\n",
        "\n",
        "**Syntax:** `###` creates a tertiary heading (H3).\n",
        "\n",
        "[Content for Preprocessing]\n",
        "\n",
        "**Example Syntax for Content:**\n",
        "*   **Bold text:** `**text**`\n",
        "*   *Italic text*: `*text*`\n",
        "*   Bullet point list:\n",
        "    * Item 1\n",
        "    * Item 2\n",
        "\n",
        "Markdown Syntax to Add Image: `![Description of the Image](./your_local_folder/name_of_the_image.png)`\n",
        "\n",
        "![Example Markdown Syntax to Add Image](https://github.com/equation-Chris/DM2025-Lab2-Exercise/blob/main/pics/example_md_img.png?raw=1)\n",
        "\n",
        "### 1.2 Feature Engineering Steps\n",
        "\n",
        "[Content for Feature Engineering]\n",
        "\n",
        "### 1.3 Explanation of Your Model\n",
        "\n",
        "[Content for Model Explanation]\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Bonus Section (5 pts Optional)\n",
        "\n",
        "**Add more detail in previous sections**\n",
        "\n",
        "### 2.1 Mention Different Things You Tried\n",
        "\n",
        "[Content for Experiments]\n",
        "\n",
        "### 2.2 Mention Insights You Gained\n",
        "\n",
        "[Content for Insights]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvAwL6wbtrgo"
      },
      "source": [
        "**`From here on starts the code section for the competition.`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6FcuP7Gtrgo"
      },
      "source": [
        "# **Competition Code**\n",
        "\n",
        "## 1. Preprocessing Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hOLU-cSstrgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c58a704-df2c-41cd-85fe-8ce0380650c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emotion_df: (47890, 2) columns: ['id', 'emotion']\n",
            "data_id_df: (64171, 2) columns: ['id', 'split']\n",
            "sample_sub_df: (16281, 2) columns: ['id', 'emotion']\n",
            "posts_df (raw) shape: (64171, 4)\n",
            "posts_df (id + text) shape: (64171, 2)\n",
            "         id                                               text\n",
            "0  0x61fc95  We got the ranch, loaded our guns and sat up t...\n",
            "1  0x35663e  I bet there is an army of married couples who ...\n",
            "2  0xc78afe                         This could only end badly.\n",
            "3  0x90089c  My sister squeezed a lime in her milk when she...\n",
            "4  0xaba820         and that got my head bobbing a little bit.\n",
            "train_df shape: (47890, 4)\n",
            "test_df shape: (16281, 3)\n",
            "         id                                               text emotion\n",
            "0  0x35663e  I bet there is an army of married couples who ...     joy\n",
            "1  0xc78afe                         This could only end badly.    fear\n",
            "2  0x90089c  My sister squeezed a lime in her milk when she...     joy\n",
            "3  0x2ffb63                                Thank you so muchâ¤ï¸     joy\n",
            "4  0x989146  Stinks because ive been in this program for a ...     joy\n",
            "Columns in train_df: ['id', 'text', 'split', 'emotion', 'clean_text']\n",
            "Columns in test_df: ['id', 'text', 'split', 'clean_text']\n",
            "                                                text  \\\n",
            "0  I bet there is an army of married couples who ...   \n",
            "1                         This could only end badly.   \n",
            "2  My sister squeezed a lime in her milk when she...   \n",
            "3                                Thank you so muchâ¤ï¸   \n",
            "4  Stinks because ive been in this program for a ...   \n",
            "\n",
            "                                          clean_text emotion  \n",
            "0  i bet there is an army of married couples who ...     joy  \n",
            "1                          this could only end badly    fear  \n",
            "2  my sister squeezed a lime in her milk when she...     joy  \n",
            "3                                  thank you so much     joy  \n",
            "4  stinks because ive been in this program for a ...     joy  \n",
            "                                                text  \\\n",
            "0  We got the ranch, loaded our guns and sat up t...   \n",
            "4         and that got my head bobbing a little bit.   \n",
            "5                Same. Glad it's not just out store.   \n",
            "6  Like always i will wait and see thanks for the...   \n",
            "8  There's a bit of room between \"not loving sub-...   \n",
            "\n",
            "                                          clean_text  \n",
            "0  we got the ranch loaded our guns and sat up ti...  \n",
            "4          and that got my head bobbing a little bit  \n",
            "5                  same glad it s not just out store  \n",
            "6  like always i will wait and see thanks for the...  \n",
            "8  there s a bit of room between not loving sub z...  \n"
          ]
        }
      ],
      "source": [
        "### Preprocessing: load data, flatten JSON, merge train/test, and clean text\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "\n",
        "# 1. Column name constants (match your CSVs)\n",
        "ID_COL = \"id\"          # id column in emotion.csv and data_identification.csv\n",
        "LABEL_COL = \"emotion\"  # label column in emotion.csv\n",
        "SUBSET_COL = \"split\"   # split column in data_identification.csv (\"train\"/\"test\")\n",
        "\n",
        "# 2. Load CSV files\n",
        "emotion_df = pd.read_csv(\"emotion.csv\")\n",
        "data_id_df = pd.read_csv(\"data_identification.csv\")\n",
        "sample_sub_df = pd.read_csv(\"samplesubmission.csv\")\n",
        "\n",
        "print(\"emotion_df:\", emotion_df.shape, \"columns:\", emotion_df.columns.tolist())\n",
        "print(\"data_id_df:\", data_id_df.shape, \"columns:\", data_id_df.columns.tolist())\n",
        "print(\"sample_sub_df:\", sample_sub_df.shape, \"columns:\", sample_sub_df.columns.tolist())\n",
        "\n",
        "# 3. Load JSON file with posts and flatten it\n",
        "with open(\"final_posts.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    posts = json.load(f)\n",
        "\n",
        "posts_df = pd.json_normalize(posts)\n",
        "print(\"posts_df (raw) shape:\", posts_df.shape)\n",
        "\n",
        "# Choose correct text/id columns\n",
        "TEXT_COL = \"root._source.post.text\"\n",
        "POST_ID_COL = \"root._source.post.post_id\"\n",
        "\n",
        "# Keep only id + text and rename to match CSV id column\n",
        "posts_df = posts_df[[POST_ID_COL, TEXT_COL]].copy()\n",
        "posts_df.rename(columns={POST_ID_COL: ID_COL, TEXT_COL: \"text\"}, inplace=True)\n",
        "\n",
        "print(\"posts_df (id + text) shape:\", posts_df.shape)\n",
        "print(posts_df.head())\n",
        "\n",
        "# 4. Merge posts with split information (train/test)\n",
        "full_df = posts_df.merge(\n",
        "    data_id_df[[ID_COL, SUBSET_COL]],\n",
        "    how=\"inner\",\n",
        "    on=ID_COL,\n",
        ")\n",
        "\n",
        "# Train part: rows with split == \"train\", then merge labels\n",
        "train_df = full_df[full_df[SUBSET_COL] == \"train\"].merge(\n",
        "    emotion_df[[ID_COL, LABEL_COL]],\n",
        "    how=\"left\",\n",
        "    on=ID_COL,\n",
        ")\n",
        "\n",
        "# Test part: rows with split == \"test\" (no labels)\n",
        "test_df = full_df[full_df[SUBSET_COL] == \"test\"].copy()\n",
        "\n",
        "print(\"train_df shape:\", train_df.shape)\n",
        "print(\"test_df shape:\", test_df.shape)\n",
        "print(train_df[[ID_COL, \"text\", LABEL_COL]].head())\n",
        "\n",
        "# 5. Text cleaning function\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Basic text normalization for tweets.\"\"\"\n",
        "    text = str(text).lower()                     # lowercase\n",
        "    text = re.sub(r\"http\\S+\", \" \", text)        # remove URLs\n",
        "    text = re.sub(r\"@\\w+\", \" \", text)           # remove @mentions\n",
        "    text = re.sub(r\"#\", \" \", text)              # remove '#' but keep hashtag word\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)       # keep only letters and spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()    # collapse multiple spaces\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to train and test texts\n",
        "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
        "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text)\n",
        "\n",
        "print(\"Columns in train_df:\", train_df.columns.tolist())\n",
        "print(\"Columns in test_df:\", test_df.columns.tolist())\n",
        "print(train_df[[\"text\", \"clean_text\", LABEL_COL]].head())\n",
        "print(test_df[[\"text\", \"clean_text\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO25ucDKtrgp"
      },
      "source": [
        "## 2. Feature Engineering Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "iEEs1Xdktrgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e82703e-7053-4e14-8bf2-91a63028ece3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (40706, 74790)\n",
            "X_valid shape: (7184, 74790)\n",
            "X_test  shape: (16281, 74790)\n"
          ]
        }
      ],
      "source": [
        "### Feature Engineering: combine word- and char-level TF-IDF features\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# 1. Extract cleaned texts and labels from train_df\n",
        "X_text = train_df[\"clean_text\"].values          # preprocessed tweets\n",
        "y = train_df[\"emotion\"].values                  # target labels\n",
        "\n",
        "# 2. Split into training and validation sets (hold-out)\n",
        "X_train_text, X_valid_text, y_train, y_valid = train_test_split(\n",
        "    X_text,\n",
        "    y,\n",
        "    test_size=0.15,      # 15% for validation, 85% for training\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 3. Word-level TF-IDF (unigrams + bigrams)\n",
        "word_tfidf = TfidfVectorizer(\n",
        "    analyzer=\"word\",\n",
        "    ngram_range=(1, 2),\n",
        "    max_features=40000,\n",
        "    min_df=3,\n",
        "    max_df=0.90,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "X_train_word = word_tfidf.fit_transform(X_train_text)\n",
        "X_valid_word = word_tfidf.transform(X_valid_text)\n",
        "X_test_word  = word_tfidf.transform(test_df[\"clean_text\"].values)\n",
        "\n",
        "# 4. Character-level TF-IDF (3- to 5-gram characters)\n",
        "char_tfidf = TfidfVectorizer(\n",
        "    analyzer=\"char\",\n",
        "    ngram_range=(3, 5),\n",
        "    max_features=40000,\n",
        "    min_df=5,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "X_train_char = char_tfidf.fit_transform(X_train_text)\n",
        "X_valid_char = char_tfidf.transform(X_valid_text)\n",
        "X_test_char  = char_tfidf.transform(test_df[\"clean_text\"].values)\n",
        "\n",
        "# 5. Concatenate word and char features horizontally\n",
        "X_train = hstack([X_train_word, X_train_char])\n",
        "X_valid = hstack([X_valid_word, X_valid_char])\n",
        "X_test  = hstack([X_test_word,  X_test_char])\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "print(\"X_test  shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITM_q9UMtrgp"
      },
      "source": [
        "## 3. Model Implementation Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hdZAgo0vtrgp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "a2b19764-16c3-46c5-a98c-fc4aacb2618d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best parameters from CV: {'C': 0.25, 'class_weight': 'balanced'}\n",
            "Best CV F1 (macro): 0.4533\n",
            "Validation accuracy (hold-out): 0.6115\n",
            "Validation F1 (macro, hold-out): 0.4640\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id   emotion\n",
              "0  0x42a94c  surprise\n",
              "1  0xbc5e67     anger\n",
              "2  0xdb5812      fear\n",
              "3  0x0e9e68       joy\n",
              "4  0xf085f1       joy"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aaaf73c1-9ff4-4feb-8542-659d61dee755\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x42a94c</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0xbc5e67</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0xdb5812</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x0e9e68</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0xf085f1</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aaaf73c1-9ff4-4feb-8542-659d61dee755')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aaaf73c1-9ff4-4feb-8542-659d61dee755 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aaaf73c1-9ff4-4feb-8542-659d61dee755');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f282ce1f-bcde-4f57-bb65-eaf049e72ac1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f282ce1f-bcde-4f57-bb65-eaf049e72ac1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f282ce1f-bcde-4f57-bb65-eaf049e72ac1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission",
              "summary": "{\n  \"name\": \"submission\",\n  \"rows\": 16281,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16281,\n        \"samples\": [\n          \"0xe5c859\",\n          \"0xbe6d01\",\n          \"0x206393\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"surprise\",\n          \"anger\",\n          \"disgust\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "### Model: tune LinearSVC, evaluate on validation, and create submission\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from scipy.sparse import vstack, hstack\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define base classifier and hyperparameter grid\n",
        "base_clf = LinearSVC(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    \"C\": [0.25, 0.5, 1.0, 2.0],          # regularization strength\n",
        "    \"class_weight\": [None, \"balanced\"]   # handle class imbalance or not\n",
        "}\n",
        "\n",
        "# 2. Set up cross-validation on the training split\n",
        "cv = StratifiedKFold(\n",
        "    n_splits=3,\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=base_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"f1_macro\",   # optimize macro F1\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 3. Run grid search on the training split (X_train, y_train)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters from CV:\", grid.best_params_)\n",
        "print(f\"Best CV F1 (macro): {grid.best_score_:.4f}\")\n",
        "\n",
        "# 4. Evaluate the best model on the validation set (hold-out)\n",
        "best_clf = grid.best_estimator_\n",
        "\n",
        "y_valid_pred = best_clf.predict(X_valid)\n",
        "\n",
        "val_acc = accuracy_score(y_valid, y_valid_pred)\n",
        "val_f1_macro = f1_score(y_valid, y_valid_pred, average=\"macro\")\n",
        "\n",
        "print(f\"Validation accuracy (hold-out): {val_acc:.4f}\")\n",
        "print(f\"Validation F1 (macro, hold-out): {val_f1_macro:.4f}\")\n",
        "\n",
        "# 5. Retrain a final model on ALL labeled data (train + valid)\n",
        "\n",
        "X_full = vstack([X_train, X_valid])\n",
        "y_full = np.concatenate([y_train, y_valid])\n",
        "\n",
        "final_clf = LinearSVC(\n",
        "    C=best_clf.C,\n",
        "    class_weight=best_clf.class_weight,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "final_clf.fit(X_full, y_full)\n",
        "\n",
        "# 6. Prepare test set in the same id order as sample_sub_df\n",
        "test_for_pred = sample_sub_df[[\"id\"]].merge(\n",
        "    test_df[[\"id\", \"clean_text\"]],\n",
        "    on=\"id\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Build word + char features for the test set\n",
        "X_test_word  = word_tfidf.transform(test_for_pred[\"clean_text\"].values)\n",
        "X_test_char  = char_tfidf.transform(test_for_pred[\"clean_text\"].values)\n",
        "X_test_all   = hstack([X_test_word, X_test_char])\n",
        "\n",
        "# 7. Predict labels for the test set using the final model\n",
        "test_pred = final_clf.predict(X_test_all)\n",
        "\n",
        "# 8. Fill predictions into the sample submission format\n",
        "submission = sample_sub_df.copy()    # columns: ['id', 'emotion']\n",
        "submission[\"emotion\"] = test_pred    # overwrite the emotion column with our predictions\n",
        "\n",
        "# 9. Save the submission file\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "submission.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**devolop research(not include in this notebook)**"
      ],
      "metadata": {
        "id": "2GoL59kOMSuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emoji nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60R3VkYhMQzm",
        "outputId": "4b2ae068-4833-4fca-e4a0-64f793a6c3e8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Preprocessing: load data, flatten JSON, merge train/test, and clean text\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import emoji\n",
        "import numpy as np\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, vstack\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# 1. Column name constants\n",
        "ID_COL = \"id\"\n",
        "LABEL_COL = \"emotion\"\n",
        "SUBSET_COL = \"split\"\n",
        "\n",
        "# 2. Load CSV files\n",
        "emotion_df = pd.read_csv(\"emotion.csv\")\n",
        "data_id_df = pd.read_csv(\"data_identification.csv\")\n",
        "sample_sub_df = pd.read_csv(\"samplesubmission.csv\")\n",
        "\n",
        "print(\"--- Data Loading ---\")\n",
        "print(\"emotion_df:\", emotion_df.shape, \"columns:\", emotion_df.columns.tolist())\n",
        "print(\"data_id_df:\", data_id_df.shape, \"columns:\", data_id_df.columns.tolist())\n",
        "print(\"sample_sub_df:\", sample_sub_df.shape, \"columns:\", sample_sub_df.columns.tolist())\n",
        "\n",
        "# 3. Load JSON file with posts and flatten it\n",
        "with open(\"final_posts.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    posts = json.load(f)\n",
        "\n",
        "posts_df = pd.json_normalize(posts)\n",
        "print(\"posts_df (raw) shape:\", posts_df.shape)\n",
        "\n",
        "# Choose correct text/id columns\n",
        "TEXT_COL = \"root._source.post.text\"\n",
        "POST_ID_COL = \"root._source.post.post_id\"\n",
        "\n",
        "# Keep only id + text and rename to match CSV id column\n",
        "posts_df = posts_df[[POST_ID_COL, TEXT_COL]].copy()\n",
        "posts_df.rename(columns={POST_ID_COL: ID_COL, TEXT_COL: \"text\"}, inplace=True)\n",
        "\n",
        "print(\"posts_df (id + text) shape:\", posts_df.shape)\n",
        "print(posts_df.head())\n",
        "\n",
        "# 4. Merge posts with split information (train/test)\n",
        "full_df = posts_df.merge(\n",
        "    data_id_df[[ID_COL, SUBSET_COL]],\n",
        "    how=\"inner\",\n",
        "    on=ID_COL,\n",
        ")\n",
        "\n",
        "# Train part: rows with split == \"train\", then merge labels\n",
        "train_df = full_df[full_df[SUBSET_COL] == \"train\"].merge(\n",
        "    emotion_df[[ID_COL, LABEL_COL]],\n",
        "    how=\"left\",\n",
        "    on=ID_COL,\n",
        ")\n",
        "\n",
        "# Test part: rows with split == \"test\" (no labels)\n",
        "test_df = full_df[full_df[SUBSET_COL] == \"test\"].copy()\n",
        "\n",
        "print(\"\\n--- Data Splitting ---\")\n",
        "print(\"train_df shape:\", train_df.shape)\n",
        "print(\"test_df shape:\", test_df.shape)\n",
        "print(train_df[[ID_COL, \"text\", LABEL_COL]].head())\n",
        "\n",
        "# 5. Optimized Text cleaning function (Preserve Emojis and tone)\n",
        "def clean_text_optimized(text: str) -> str:\n",
        "    text = str(text)\n",
        "    # Convert Emojis to text description (e.g., ðŸ˜­ -> :loudly_crying_face:)\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \" \", text)  # remove URLs\n",
        "    text = re.sub(r\"@\\w+\", \" \", text)     # remove @mentions\n",
        "    text = re.sub(r\"#\", \" \", text)        # remove hash sign\n",
        "    # Keep letters, numbers, colons (for emojis), exclamation marks, question marks\n",
        "    text = re.sub(r\"[^a-z0-9\\s:!?_]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply cleaning\n",
        "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text_optimized)\n",
        "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text_optimized)\n",
        "\n",
        "print(\"\\n--- Text Cleaning (Comparison) ---\")\n",
        "print(train_df[[\"text\", \"clean_text\", LABEL_COL]].head())\n",
        "print(test_df[[\"text\", \"clean_text\"]].head())\n",
        "\n",
        "### Feature Engineering: combine word- and char-level TF-IDF features\n",
        "\n",
        "# 1. Extract cleaned texts and labels from train_df\n",
        "X_text = train_df[\"clean_text\"].values\n",
        "y = train_df[\"emotion\"].values\n",
        "\n",
        "# 2. Split into training and validation sets (hold-out) for evaluation metrics\n",
        "X_train_text, X_valid_text, y_train, y_valid = train_test_split(\n",
        "    X_text,\n",
        "    y,\n",
        "    test_size=0.15,      # 15% for validation\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 3. Optimized Tokenizer\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "def my_tokenizer(text):\n",
        "    return tokenizer.tokenize(text)\n",
        "\n",
        "print(\"\\n--- Feature Engineering ---\")\n",
        "# 4. Word-level TF-IDF (Enhanced)\n",
        "word_tfidf = TfidfVectorizer(\n",
        "    tokenizer=my_tokenizer,\n",
        "    ngram_range=(1, 3),      # 1-3 grams\n",
        "    max_features=50000,\n",
        "    min_df=2,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "print(\"Fitting Word TF-IDF...\")\n",
        "X_train_word = word_tfidf.fit_transform(X_train_text)\n",
        "X_valid_word = word_tfidf.transform(X_valid_text)\n",
        "X_test_word  = word_tfidf.transform(test_df[\"clean_text\"].values)\n",
        "\n",
        "# 5. Character-level TF-IDF (Enhanced)\n",
        "char_tfidf = TfidfVectorizer(\n",
        "    analyzer=\"char\",\n",
        "    ngram_range=(3, 6),      # 3-6 grams\n",
        "    max_features=30000,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "print(\"Fitting Char TF-IDF...\")\n",
        "X_train_char = char_tfidf.fit_transform(X_train_text)\n",
        "X_valid_char = char_tfidf.transform(X_valid_text)\n",
        "X_test_char  = char_tfidf.transform(test_df[\"clean_text\"].values)\n",
        "\n",
        "# 6. Concatenate\n",
        "X_train = hstack([X_train_word, X_train_char])\n",
        "X_valid = hstack([X_valid_word, X_valid_char])\n",
        "X_test  = hstack([X_test_word,  X_test_char])\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "print(\"X_test  shape:\", X_test.shape)\n",
        "\n",
        "### Model: Ensemble Voting Classifier\n",
        "\n",
        "print(\"\\n--- Model Training & Evaluation ---\")\n",
        "\n",
        "# 1. Define base classifiers\n",
        "clf1 = LinearSVC(C=1.0, class_weight=\"balanced\", random_state=42, max_iter=10000)\n",
        "clf2 = LogisticRegression(C=2.0, class_weight=\"balanced\", solver='liblinear', random_state=42, max_iter=1000)\n",
        "clf3 = ComplementNB(alpha=0.5)\n",
        "\n",
        "# 2. Ensemble\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('svc', clf1), ('lr', clf2), ('nb', clf3)],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "# 3. Cross-Validation (Simulating GridSearch Best Score)\n",
        "# Calculate CV score here to replace the original GridSearch \"Best CV F1\"\n",
        "cv_scores = cross_val_score(voting_clf, X_train, y_train, cv=3, scoring=\"f1_macro\", n_jobs=-1)\n",
        "print(f\"Ensemble Cross-Validation F1 (macro): {cv_scores.mean():.4f}\")\n",
        "\n",
        "# 4. Train on split-train and Evaluate on split-valid\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_valid_pred = voting_clf.predict(X_valid)\n",
        "\n",
        "val_acc = accuracy_score(y_valid, y_valid_pred)\n",
        "val_f1_macro = f1_score(y_valid, y_valid_pred, average=\"macro\")\n",
        "\n",
        "print(f\"Validation accuracy (hold-out): {val_acc:.4f}\")\n",
        "print(f\"Validation F1 (macro, hold-out): {val_f1_macro:.4f}\")\n",
        "\n",
        "# 5. Retrain on ALL labeled data (train + valid)\n",
        "print(\"\\n--- Retraining on Full Data ---\")\n",
        "X_full = vstack([X_train, X_valid])\n",
        "y_full = np.concatenate([y_train, y_valid])\n",
        "\n",
        "final_clf = VotingClassifier(\n",
        "    estimators=[('svc', clf1), ('lr', clf2), ('nb', clf3)],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "final_clf.fit(X_full, y_full)\n",
        "print(\"Final model trained.\")\n",
        "\n",
        "# 6. Predict on Test\n",
        "# Prepare test set in the same id order as sample_sub_df\n",
        "test_for_pred = sample_sub_df[[\"id\"]].merge(\n",
        "    test_df[[\"id\", \"clean_text\"]],\n",
        "    on=\"id\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Build features for test set\n",
        "X_test_word_final = word_tfidf.transform(test_for_pred[\"clean_text\"].values)\n",
        "X_test_char_final = char_tfidf.transform(test_for_pred[\"clean_text\"].values)\n",
        "X_test_all = hstack([X_test_word_final, X_test_char_final])\n",
        "\n",
        "# 7. Predict\n",
        "test_pred = final_clf.predict(X_test_all)\n",
        "\n",
        "# 8. Submission\n",
        "submission = sample_sub_df.copy()\n",
        "submission[\"emotion\"] = test_pred\n",
        "submission.to_csv(\"submission_optimized.csv\", index=False)\n",
        "\n",
        "print(\"\\n--- Submission Generated ---\")\n",
        "print(submission.head())\n",
        "print(\"Saved to submission_optimized.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqq1Up0BMDBD",
        "outputId": "373003dd-7bb4-4840-d431-5d0cf2e2cf60"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Loading ---\n",
            "emotion_df: (47890, 2) columns: ['id', 'emotion']\n",
            "data_id_df: (64171, 2) columns: ['id', 'split']\n",
            "sample_sub_df: (16281, 2) columns: ['id', 'emotion']\n",
            "posts_df (raw) shape: (64171, 4)\n",
            "posts_df (id + text) shape: (64171, 2)\n",
            "         id                                               text\n",
            "0  0x61fc95  We got the ranch, loaded our guns and sat up t...\n",
            "1  0x35663e  I bet there is an army of married couples who ...\n",
            "2  0xc78afe                         This could only end badly.\n",
            "3  0x90089c  My sister squeezed a lime in her milk when she...\n",
            "4  0xaba820         and that got my head bobbing a little bit.\n",
            "\n",
            "--- Data Splitting ---\n",
            "train_df shape: (47890, 4)\n",
            "test_df shape: (16281, 3)\n",
            "         id                                               text emotion\n",
            "0  0x35663e  I bet there is an army of married couples who ...     joy\n",
            "1  0xc78afe                         This could only end badly.    fear\n",
            "2  0x90089c  My sister squeezed a lime in her milk when she...     joy\n",
            "3  0x2ffb63                                Thank you so muchâ¤ï¸     joy\n",
            "4  0x989146  Stinks because ive been in this program for a ...     joy\n",
            "\n",
            "--- Text Cleaning (Comparison) ---\n",
            "                                                text  \\\n",
            "0  I bet there is an army of married couples who ...   \n",
            "1                         This could only end badly.   \n",
            "2  My sister squeezed a lime in her milk when she...   \n",
            "3                                Thank you so muchâ¤ï¸   \n",
            "4  Stinks because ive been in this program for a ...   \n",
            "\n",
            "                                          clean_text emotion  \n",
            "0  i bet there is an army of married couples who ...     joy  \n",
            "1                          this could only end badly    fear  \n",
            "2  my sister squeezed a lime in her milk when she...     joy  \n",
            "3                        thank you so much red_heart     joy  \n",
            "4  stinks because ive been in this program for a ...     joy  \n",
            "                                                text  \\\n",
            "0  We got the ranch, loaded our guns and sat up t...   \n",
            "4         and that got my head bobbing a little bit.   \n",
            "5                Same. Glad it's not just out store.   \n",
            "6  Like always i will wait and see thanks for the...   \n",
            "8  There's a bit of room between \"not loving sub-...   \n",
            "\n",
            "                                          clean_text  \n",
            "0  we got the ranch loaded our guns and sat up ti...  \n",
            "4          and that got my head bobbing a little bit  \n",
            "5                  same glad it s not just out store  \n",
            "6  like always i will wait and see thanks for the...  \n",
            "8  there s a bit of room between not loving sub z...  \n",
            "\n",
            "--- Feature Engineering ---\n",
            "Fitting Word TF-IDF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting Char TF-IDF...\n",
            "X_train shape: (40706, 80000)\n",
            "X_valid shape: (7184, 80000)\n",
            "X_test  shape: (16281, 80000)\n",
            "\n",
            "--- Model Training & Evaluation ---\n",
            "Ensemble Cross-Validation F1 (macro): 0.4640\n",
            "Validation accuracy (hold-out): 0.6283\n",
            "Validation F1 (macro, hold-out): 0.4757\n",
            "\n",
            "--- Retraining on Full Data ---\n",
            "Final model trained.\n",
            "\n",
            "--- Submission Generated ---\n",
            "         id   emotion\n",
            "0  0x42a94c  surprise\n",
            "1  0xbc5e67     anger\n",
            "2  0xdb5812      fear\n",
            "3  0x0e9e68       joy\n",
            "4  0xf085f1       joy\n",
            "Saved to submission_optimized.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DM2025-Lab2-Exercise",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}